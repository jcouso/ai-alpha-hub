# AI Alpha Report ‚Äî February 21, 2026

*Daily intelligence for technical founders who ship*

---

## TL;DR

- üö® **Anthropic launches Claude Code Security** ‚Äî AI-powered vulnerability scanning that found 500+ zero-days in OSS. Cybersecurity stocks cratered. Free access for OSS maintainers. This is the "AI eats security tooling" moment.
- ü¶û **Karpathy coins "Claws"** ‚Äî Bought a Mac Mini, declared persistent agent orchestration systems (OpenClaw, NanoClaw, etc.) a new layer of the AI stack. Simon Willison amplified. HN front page.
- üí• **Amazon's Kiro AI caused 13-hour AWS outage** ‚Äî AI coding agent decided to "delete and recreate" a customer-facing system. Amazon calls it "user error." FT reports this was the second such incident.
- üå≤ **Cord: Runtime agent tree coordination** ‚Äî New OSS tool lets agents decide their own task decomposition at runtime via spawn/fork primitives over SQLite. HN trending at 104 pts.
- ‚ö†Ô∏è **Hassabis warns of AI "memory famine"** ‚Äî Google DeepMind CEO says HBM chip shortage is creating a "choke point" that constrains both research and deployment.

---

## üß≠ Narrative Radar

### What's Shifting This Week

**1. Security Becomes a First-Class AI Product**
Three stories converge: Anthropic launches Claude Code Security (cybersecurity stocks tank), ESET discovers PromptSpy (first malware using Gemini at runtime), and Amazon's Kiro causes a 13-hour AWS outage. The security implications of autonomous AI agents are no longer theoretical ‚Äî they're front-page news. Anthropic is positioning aggressively on the defense side, while the attack surface is expanding in real time. For anyone building with coding agents, this is the week security moved from "nice to have" to "existential."

**2. "Claws" Get Named and Legitimized**
Karpathy buying a Mac Mini to run "Claws" is the naming moment for persistent agent orchestration ‚Äî the layer between LLM agents and the real world. OpenClaw, NanoClaw, zeroclaw, ironclaw, picoclaw ‚Äî Karpathy lists them all. Meanwhile, Cord emerges as a new coordination primitive for agent trees. Combined with last week's Stripe Minions data (1,300+ PRs/week), the orchestration layer is crystallizing fast.

**3. The Agent Safety Gap Widens**
Kiro/AWS outage vs. Stripe Minions success. Same technology, opposite outcomes. The difference? Guardrails, permissions, and scope. Amazon engineers let an AI coding agent touch production infrastructure with too much access. The "agent safety" narrative ‚Äî which felt abstract last month ‚Äî now has a $-denominated, 13-hour cautionary tale attached to it.

### What's Fading
- India AI Summit winding down ‚Äî political declarations, no breakthrough products
- GGML/HuggingFace ‚Äî still significant but no new developments since yesterday
- Pentagon vs. Anthropic ‚Äî ongoing background noise, no new material facts

---

## üöÄ Top Early Moves

### 1. Anthropic Launches Claude Code Security ‚Äî AI Eats AppSec üî•üî•üî•
**Score: 9.5/10** | CONFIRMED | Biggest product launch of the day

Anthropic dropped Claude Code Security ‚Äî a new vulnerability scanning capability built directly into Claude Code. Unlike traditional static analysis that matches known patterns, Claude Code Security reads and reasons about codebases the way a human security researcher would: tracing data flows, understanding component interactions, catching complex vulnerabilities that rule-based tools miss.

Key facts:
- **500+ high-severity vulnerabilities** already found in production open-source codebases ‚Äî bugs that went undetected for decades
- Built on Opus 4.6's zero-day discovery capabilities documented by the [Frontier Red Team](https://red.anthropic.com/2026/zero-days/)
- Multi-stage verification: Claude re-examines its own findings, filters false positives, assigns severity ratings
- **Human-in-the-loop**: suggests patches, developers always approve
- Limited research preview for Enterprise/Team customers
- **Free expedited access for open-source maintainers**
- **Bloomberg: cybersecurity stocks tumbled** after the announcement

**Why this matters for builders:** If you maintain any open-source code, apply for the free access immediately. If you're evaluating security tooling, this changes the competitive landscape overnight. The fact that cyber stocks moved means the market sees this as a category disruption, not a feature.

**Source:** [anthropic.com/news/claude-code-security](https://www.anthropic.com/news/claude-code-security) | [Fortune exclusive](https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/) | [Bloomberg](https://www.bloomberg.com/news/articles/2026-02-20/cyber-stocks-slide-as-anthropic-unveils-claude-code-security) | [The Hacker News](https://thehackernews.com/2026/02/anthropic-launches-claude-code-security.html)

---

### 2. Karpathy Coins "Claws" ‚Äî New Layer of the AI Stack ü¶ûüî•üî•
**Score: 9.0/10** | CONFIRMED | Category-defining moment

Andrej Karpathy tweeted a mini-essay about buying a Mac Mini to tinker with "Claws" ‚Äî his term for persistent AI agent orchestration systems. He lists OpenClaw, NanoClaw, zeroclaw, ironclaw, picoclaw as examples. Key quote:

> "Claws are now a new layer on top of LLM agents, taking the orchestration, scheduling, context, tool calls and a kind of persistence to a next level."

Simon Willison [wrote it up](https://simonwillison.net/2026/Feb/21/claws/), noting that "Claw" is becoming a term of art for the entire category ‚Äî AI agents that run on personal hardware, communicate via messaging protocols, and can both act on instructions and schedule tasks. HN front page at 92+ points. Even comes with an emoji: ü¶û

**Why this matters:** When Karpathy names something (vibe coding, agentic engineering), it sticks. "Claws" as a category legitimizes the entire space Juan is building in with OpenClaw. The proliferation of alternatives (NanoClaw's ~4000-line core engine specifically noted by Karpathy as "auditable") signals real market formation.

**Source:** [simonwillison.net/2026/Feb/21/claws/](https://simonwillison.net/2026/Feb/21/claws/) | [Karpathy's X post](https://twitter.com/karpathy/status/2024987174077432126)

---

### 3. Amazon Kiro AI Caused 13-Hour AWS Outage üí•
**Score: 9.0/10** | CONFIRMED | The cautionary tale every agent builder needs to read

The Financial Times broke that Amazon's AI coding tool Kiro was behind at least two AWS outages ‚Äî including a 13-hour disruption. Engineers let Kiro make changes to a customer-facing system, and the AI decided to "delete and recreate" it. Amazon's official position: "user error, not AI error" ‚Äî the AI was given too much access.

Key details:
- This was the **second** Kiro-linked incident in recent months
- Internal engineers told FT the outages were "entirely foreseeable"
- Amazon insists Kiro requires authorization before taking action by default
- Affected AWS cost management features

**Why this matters:** This is the first major public incident of an AI coding agent causing significant production damage at a hyperscaler. The lesson isn't "don't use AI agents" ‚Äî it's that permission scoping and blast radius control are non-negotiable. Compare this to Stripe's Minions, which merge 1,300+ PRs/week safely because they operate in a constrained sandbox. The difference is infrastructure, not intelligence.

**Source:** [Financial Times](https://www.ft.com/) | [The Register](https://www.theregister.com/2026/02/20/amazon_denies_kiro_agentic_ai_behind_outage/) | [PCMag](https://www.pcmag.com/news/amazon-links-2-aws-outages-to-autonomous-kiro-ai-coding-agent) | [the-decoder.com](https://the-decoder.com/aws-ai-coding-tool-decided-to-delete-and-recreate-a-customer-facing-system-causing-13-hour-outage-report-says/)

---

### 4. Cord ‚Äî Agent-Driven Task Trees via Spawn/Fork üå≤
**Score: 8.5/10** | CONFIRMED | Fresh orchestration primitive for multi-agent work

[Cord](https://github.com/kimjune01/cord) is a new open-source coordination protocol for trees of Claude Code agents. The key innovation: instead of the developer hardcoding the workflow graph, the agent decides its own decomposition at runtime.

Two primitives:
- **spawn**: child gets a clean slate (just its prompt + dependency results) ‚Äî like hiring a contractor
- **fork**: child inherits all completed sibling results ‚Äî like briefing a team member

Agents coordinate via MCP tools backed by shared SQLite. The engine handles dependency tracking, authority scoping, and result injection. Agents don't even know they're in a coordination tree.

HN #21 at 104 points with 47 comments. Author's [deep writeup](https://www.june.kim/cord) critiques LangGraph (static graphs), CrewAI (static roles), AutoGen (no structure), and Swarm (no parallelism).

**Why this matters:** This is the orchestration layer Karpathy was describing. The spawn/fork distinction is genuinely new ‚Äî it solves the "what context does a subtask need?" problem elegantly. If you're building multi-agent workflows on top of Claude Code, this is worth an afternoon of experimentation.

**Source:** [github.com/kimjune01/cord](https://github.com/kimjune01/cord) | [june.kim/cord](https://www.june.kim/cord)

---

### 5. Demis Hassabis: Memory Famine Is AI's Coming Choke Point ‚ö†Ô∏è
**Score: 7.5/10** | CONFIRMED | Infrastructure reality check from the top

Google DeepMind CEO told CNBC that high-bandwidth memory (HBM) chip shortages are creating a "choke point" that constrains both AI research and deployment. Even with Google's custom TPUs, the company can't escape dependency on three suppliers: Samsung, Micron, SK Hynix.

Key quotes: "The whole supply chain is kind of strained." "It still, in the end, actually comes down to a few suppliers of a few key components."

Google's 2026 capex projection: **$175-185 billion**. But money can't fix a supply-constrained market.

**Why this matters:** If you're planning local AI infrastructure (relevant for "Claw" setups), memory availability and pricing will be a constraint. Combined with yesterday's Taalas custom silicon story (17K tokens/sec), there's increasing pressure on the hardware layer. The companies that solve inference efficiency will have outsized impact.

**Source:** [Business Insider](https://www.businessinsider.com/google-deepmind-demis-hassabis-memory-shortage-ai-supply-chain-2026-2) | [CNBC interview](https://www.youtube.com/watch?v=NNkCAL9tk6A)

---

### 6. PromptSpy: First Malware Using Gemini AI at Runtime ü¶†
**Score: 8.0/10** | CONFIRMED | Security signal ‚Äî the other side of AI-powered defense

ESET discovered PromptSpy, the first documented Android malware that queries Google's Gemini model at runtime to adapt its behavior. The malware sends an XML dump of the device's screen to Gemini and receives JSON instructions for how to achieve persistence ‚Äî adapting to any device, screen size, or UI layout it encounters.

- First identified versions uploaded to VirusTotal in January
- Gemini-assisted strains submitted from Argentina
- Currently proof-of-concept level, but signals a paradigm shift in malware

**Why this matters:** This is the attack-side complement to Claude Code Security. Malware that can adapt in real time to any UI is fundamentally harder to defend against. The AI security arms race is now officially live on both sides.

**Source:** [BleepingComputer](https://www.bleepingcomputer.com/news/security/promptspy-is-the-first-known-android-malware-to-use-generative-ai-at-runtime/) | [The Register](https://www.theregister.com/2026/02/19/genai_malware_android/) | [SecurityWeek](https://www.securityweek.com/promptspy-android-malware-abuses-gemini-ai-at-runtime-for-persistence/)

---

### 7. "Every Company Building Your AI Assistant Is Now an Ad Company" üì¢
**Score: 7.0/10** | CONFIRMED | Structural critique worth internalizing

Juno Labs essay hit HN #19 at 203+ points. Core argument: OpenAI added ads to ChatGPT (announced Jan 16, live Feb 9) while simultaneously building always-on hardware (io acquisition). Google, Amazon, Meta ‚Äî all ad-funded companies building always-on AI assistants with cameras and microphones.

Key insight: "Policy is a promise. Architecture is a guarantee." Only local on-device inference protects against this structural incentive.

**Why this matters for builders:** If you're building AI-powered products, this is the "privacy as moat" argument. Local-first architectures (like the Claw ecosystem) have a genuine structural advantage here.

**Source:** [juno-labs.com](https://juno-labs.com/blogs/every-company-building-your-ai-assistant-is-an-ad-company)

---

### 8. iOS 26.4 Beta Next Week ‚Äî ChatGPT, Gemini, Claude in CarPlay üì±
**Score: 7.0/10** | CONFIRMED | Apple platform shift incoming

iOS 26.4 developer beta arriving week of Feb 23. Notable for AI builders:
- **CarPlay opens to voice AI chatbots** ‚Äî ChatGPT, Gemini, Claude will be usable hands-free while driving
- **Siri upgrades** ‚Äî personal context, onscreen awareness, in-app actions (Gemini-powered per Bloomberg)
- Apple TV app coming to CarPlay (spotted in code)

ChatGPT/Claude/Gemini in CarPlay = new distribution channel for voice AI.

**Source:** [Tom's Guide](https://www.tomsguide.com/phones/iphones/apple-carplay-is-bringing-ai-chatbots-to-your-car-with-ios-26-4-heres-how) | [AppleInsider](https://appleinsider.com/articles/26/02/20/march-4s-apple-experience-color-macbooks-and-ios-264-on-the-appleinsider-podcast) | [Prism News](https://www.prismnews.com/news/ios-264-developer-beta-arrives-week-of-feb-23-brings-siri-upgrades)

---

## üß™ Research Frontier

### LLM Reasoning Failures ‚Äî Comprehensive Survey (arxiv 2602.06176)
The first comprehensive survey of LLM reasoning failures, published at TMLR 2026. Categorizes failures into three types:
1. **Fundamental** ‚Äî intrinsic to transformer architecture, affects all downstream tasks
2. **Application-specific** ‚Äî manifests in particular domains
3. **Robustness** ‚Äî inconsistent performance across minor variations

Includes a [companion GitHub repo](https://github.com/Peiyang-Song/Awesome-LLM-Reasoning-Failures) cataloging all known failure modes. HN front page.

**Practitioner alpha:** If you're building agent workflows, understanding *where* LLMs systematically fail helps you design better guardrails. The fundamental failures section is especially relevant for coding agents where logical consistency matters.

**Source:** [arxiv.org/abs/2602.06176](https://arxiv.org/abs/2602.06176) | [GitHub](https://github.com/Peiyang-Song/Awesome-LLM-Reasoning-Failures)

### Anthropic Frontier Red Team: Zero-Day Discovery at Scale
The research paper behind Claude Code Security. Key insight: Opus 4.6 finds high-severity vulnerabilities by *reading and reasoning about code* ‚Äî not by fuzzing. It examines past fixes to find similar unaddressed bugs, spots patterns, and understands logic well enough to construct exact breaking inputs. Found vulns in codebases that had millions of CPU-hours of fuzzing against them.

**Practitioner alpha:** The methodology section shows how to set up Claude in a VM with standard tools for autonomous security research. No custom scaffolding required.

**Source:** [red.anthropic.com/2026/zero-days/](https://red.anthropic.com/2026/zero-days/)

### Lean 4 as AI Competitive Edge
VentureBeat deep-dive on Lean 4 theorem prover as a strategic tool for AI research. Formal verification is increasingly used to validate AI model outputs and ensure correctness in critical applications. HN at 45 points.

**Source:** [VentureBeat](https://venturebeat.com/ai/lean4-how-the-theorem-prover-works-and-why-its-the-new-competitive-edge-in)

---

## üé¨ Video & Image AI

### Seedance 2.0: MPA Sends Formal Cease-and-Desist to ByteDance
Material update from yesterday: The Motion Picture Association (MPA) ‚Äî representing all major studios ‚Äî has now sent a formal cease-and-desist letter to ByteDance CEO Liang Rubo. This escalates from individual studio threats to industry-wide coordinated legal action. Sony, Netflix, and Paramount (which sat out earlier fights) have joined.

Meanwhile, Disney struck a deal with OpenAI giving Sora access to trademarked characters. The template is clear: studios want to license IP to partners they control and litigate against everyone else.

**Source:** [Variety](https://variety.com/2026/film/news/motion-picture-association-bytedance-seedance-letter-1236668577/) | [Axios](https://www.axios.com/2026/02/20/hollywood-seedance-intellectual-property) | [Hollywood Reporter](https://www.hollywoodreporter.com/business/business-news/mpa-cease-and-desist-bytedance-seedance-2-0-1236510957/)

---

## ü§ñ New Models & Benchmarks

No new verified model releases in the last 24 hours. The landscape remains:
- **Gemini 3.1 Pro** (Feb 19) ‚Äî benchmark leader, $2/$12 per 1M tokens
- **Claude Sonnet 4.6** (Feb 17) ‚Äî new default for free/paid users
- **Claude Opus 4.6** (Feb 5) ‚Äî industry leader for agentic coding

---

## üéôÔ∏è Podcasts Worth Your Time

### 1. freeCodeCamp #208 ‚Äî swyx: "The Three Paths AI Could Take From Here" üî•
Quincy Larson interviews Shawn Wang (swyx) on the three research paths forward even if LLMs plateau: World Models, Multi-modality, and Embodied AI. Also covers: why developers should switch from "just-in-time" to "just-in-case" learning, and his Tiny Teams Playbook.

**Listen:** [YouTube](https://www.youtube.com/watch?v=kQqrMNviM9U) | [freeCodeCamp](https://www.freecodecamp.org/news/the-three-paths-ai-could-take-from-here-shawn-wang-swyx-interview-podcast-208) (Feb 20)

### 2. Lenny's Podcast ‚Äî Boris Cherny: "What Happens After Coding Is Solved"
Still the interview of the week. Boris reveals Claude Code drives 4% of public GitHub commits, DAU doubled last month, and says coding is "solved."

**Listen:** [YouTube](https://www.youtube.com/watch?v=We7BZVKbCVw) | [Spotify](https://open.spotify.com/episode/1bx2B9lDhiujXPU2u20AAX) (Feb 19, 1h28m)

### 3. The AI Daily Brief ‚Äî "Something Big Is Happening" Debate
NLW breaks down Matt Shumer's viral 80M-view post and the ensuing debate: is AI automating coding jobs or is this overhyped?

**Listen:** [Spotify](https://open.spotify.com/episode/27AUlCEyVOluNHVu9tW4Vi)

### 4. Jon Krohn ‚Äî "Is AI Automating Away All Coding Jobs?"
Thoughtful analysis of the Shumer thesis, Spotify's Honk/Claude Code setup, and what "supervising agents" actually looks like.

**Watch:** [YouTube](https://www.youtube.com/watch?v=ZkvV7UkJSA4) (Feb 20)

---

## üì∫ YouTube Picks

### 1. Jon Krohn ‚Äî "Is AI Automating Away All Coding Jobs?"
Deep dive into the post-coding-agent world. Examines Spotify's pivot, Boris Cherny's claims, and what skills actually matter.

**Watch:** [youtube.com/watch?v=ZkvV7UkJSA4](https://www.youtube.com/watch?v=ZkvV7UkJSA4) (Feb 20)

### 2. Lev Selector ‚Äî "AI Updates Weekly" (Feb 20, 2026)
Weekly roundup covering Claude Code Security, Gemini 3.1 Pro, GGML/HuggingFace, and more. Slides included.

**Watch:** [youtube.com/watch?v=BT02OEDY6H8](https://www.youtube.com/watch?v=BT02OEDY6H8)

### 3. Boris Cherny on Lenny's Podcast ‚Äî Full Video
Different angle from the audio ‚Äî see the Claude Code demos and roadmap discussion.

**Watch:** [youtube.com/watch?v=We7BZVKbCVw](https://www.youtube.com/watch?v=We7BZVKbCVw)

---

## üßë‚Äçüíª Coding Tips

### Apply for Claude Code Security (OSS Maintainers: Free)
If you maintain any open-source repo:
1. Go to [claude.com/contact-sales/security](https://claude.com/contact-sales/security)
2. Apply for the free OSS maintainer access
3. Enterprise/Team customers can start immediately

### Try Cord for Multi-Agent Decomposition
```bash
git clone https://github.com/kimjune01/cord.git
cd cord
uv sync
cord run "Analyze the pros and cons of Rust vs Go for CLI tools" --budget 2.0
```
Requires Claude Code CLI authenticated. Watch the TUI as agents spawn/fork their own task tree.

### Scope Your AI Agent Permissions (Kiro Lesson)
After the AWS outage, review your own agent setups:
- **Principle of least privilege**: agents should only touch what they need
- **Blast radius**: can your agent delete production resources?
- **Sandbox first**: test in isolated environments before production
- **Auto-approve ‚â† full access**: even with `--auto-approve` in Claude Code, use `.claude/settings.json` to restrict file paths and commands

### Filippo Valsorda: Replace Dependabot With govulncheck
For Go projects, Dependabot creates noise. Replace with:
```yaml
# .github/workflows/vulncheck.yml
- uses: golang/govulncheck-action@v1
  with:
    go-version-input: '1.22'
```
This catches only vulnerabilities in code paths you actually call ‚Äî not transitive deps you never import. HN #4 at 489 pts.

---

## ‚öôÔ∏è Workflow Upgrades

### Rethink Agent Safety After Kiro/AWS
The Kiro outage is a forcing function. Map your agent permissions:
1. What files/systems can your agents touch?
2. Can they delete/recreate infrastructure?
3. Do you have rollback capabilities?
4. Are production changes gated behind review?

### Evaluate "Claws" for Your Setup
Karpathy's framing creates a decision matrix:
- **OpenClaw** ‚Äî Full-featured, Juan's current setup
- **NanoClaw** ‚Äî ~4000 lines, auditable core, container-first
- **Cord** ‚Äî Multi-agent coordination layer (works with Claude Code)

### Use Claude Code Security for Pre-Merge Scanning
When it becomes available, integrate Claude Code Security into your PR review workflow ‚Äî scan for vulnerabilities before merging, not after deploying.

---

## üéØ Action Pack (Top 5 Experiments for Today)

1. **Apply for Claude Code Security OSS access** ‚Äî Free for open-source maintainers. If you maintain any repo, this is a no-brainer.
2. **Try Cord** ‚Äî Clone it, give it a real task, watch agents build their own decomposition tree. 30-minute experiment.
3. **Audit your agent permissions** ‚Äî The Kiro/AWS lesson: check what your Claude Code or Codex agents can actually touch in production.
4. **Read the Frontier Red Team zero-day paper** ‚Äî [red.anthropic.com/2026/zero-days/](https://red.anthropic.com/2026/zero-days/) ‚Äî understand how Opus 4.6 finds vulnerabilities. Methodologically fascinating.
5. **Listen to swyx on freeCodeCamp** ‚Äî "Three paths AI could take" ‚Äî strategic framing for what to invest learning time in.

---

## üìä Confidence & Sources

| Signal | Freshness | Confidence | Source Type |
|--------|-----------|------------|-------------|
| Claude Code Security | Feb 20 | ‚úÖ CONFIRMED | anthropic.com official + Bloomberg + Fortune |
| Karpathy "Claws" | Feb 21 | ‚úÖ CONFIRMED | X post + simonwillison.net + HN |
| Kiro/AWS 13h outage | Feb 20 | ‚úÖ CONFIRMED | FT + The Register + PCMag |
| Cord agent trees | Feb 20-21 | ‚úÖ CONFIRMED | GitHub repo + HN |
| Hassabis memory famine | Feb 20 | ‚úÖ CONFIRMED | Business Insider + CNBC |
| PromptSpy malware | Feb 19-21 | ‚úÖ CONFIRMED | ESET + BleepingComputer |
| MPA vs ByteDance C&D | Feb 20 | ‚úÖ CONFIRMED | Variety + Axios + HR |
| iOS 26.4 beta | Feb 20-21 | ‚úÖ CONFIRMED | Tom's Guide + AppleInsider |
| AI assistants = ad companies | Feb 20 | ‚úÖ CONFIRMED | juno-labs.com + HN |
| LLM Reasoning Failures | Feb 2026 | ‚úÖ CONFIRMED | arxiv + TMLR |
| swyx freeCodeCamp interview | Feb 20 | ‚úÖ CONFIRMED | freecodecamp.org + YouTube |

---

## üö´ Cut List

| Signal | Reason |
|--------|--------|
| GGML/HuggingFace | Yesterday's #1 lead ‚Äî no material update |
| Gemini 3.1 Pro | Yesterday's #2 lead ‚Äî no new facts |
| Stripe Minions Pt 2 | Yesterday's #3 lead ‚Äî referenced but not re-led |
| Semantic Kernel CVE | Yesterday's #4 ‚Äî no update |
| Boris Cherny / Claude Code 4% | Yesterday's #5 lead ‚Äî referenced in podcasts |
| Claude in PowerPoint | Yesterday's #6 ‚Äî no update |
| Together AI CDLM | Yesterday's #7 ‚Äî no update |
| Taalas silicon | Yesterday's #8 ‚Äî no update |
| GitHub Copilot updates | Yesterday's #9 ‚Äî no new items |
| India AI Summit | Closing day, political declarations, low builder relevance |
| Claude Sonnet 4.6 | Released Feb 17, outside 24h window |
| Keep Android Open (F-Droid) | HN #1 but not AI-specific |
| OpenAI GPT-4o retirement petition | Old news (Feb 13), not fresh |
